{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Artificial Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       2       0.00              1          1               1   \n",
       "1       1   83807.86              1          0               1   \n",
       "2       8  159660.80              3          1               0   \n",
       "3       1       0.00              2          0               0   \n",
       "4       2  125510.82              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing the dataset\n",
    "dataset = pd.read_csv('Churn_Modelling.csv')\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exited\n",
       "0    7963\n",
       "1    2037\n",
       "Name: Exited, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.groupby(['Exited'])['Exited'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset.iloc[:, 3:13].values\n",
    "y = dataset.iloc[:, 13].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder_X_1 = LabelEncoder()\n",
    "X[:, 1] = labelencoder_X_1.fit_transform(X[:, 1])\n",
    "labelencoder_X_2 = LabelEncoder()\n",
    "X[:, 2] = labelencoder_X_2.fit_transform(X[:, 2])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [1])\n",
    "X = onehotencoder.fit_transform(X).toarray()\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size = 0.2, \n",
    "                                                    random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Create the ANN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the Keras libraries and packages\n",
    "import keras\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model,Sequential,load_model\n",
    "from keras.layers import Input, Flatten, Dense, Dropout\n",
    "from keras.layers.merge import concatenate\n",
    "from keras import backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    def recall(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "    precision = precision(y_true, y_pred)\n",
    "    recall = recall(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialising the ANN\n",
    "classifier = Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the input layer and the first hidden layer\n",
    "classifier.add(Dense(units = X_train.shape[1], \n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'relu', \n",
    "                     input_dim = X_train.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the second hidden layer\n",
    "classifier.add(Dense(units = 6, \n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a Dropout\n",
    "classifier.add(Dropout(rate = 0.2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the output layer\n",
    "classifier.add(Dense(units = 1, \n",
    "                     kernel_initializer = 'uniform', \n",
    "                     activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the ANN\n",
    "classifier.compile(optimizer = 'adamax', \n",
    "                   loss = 'binary_crossentropy', \n",
    "                   metrics = ['accuracy',f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8000, 11)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/5\n",
      "8000/8000 [==============================] - 3s 437us/step - loss: 0.4003 - acc: 0.8319 - f1: 0.3179 - val_loss: 0.3770 - val_acc: 0.8515 - val_f1: 0.4352\n",
      "Epoch 2/5\n",
      "8000/8000 [==============================] - 3s 334us/step - loss: 0.3916 - acc: 0.8392 - f1: 0.3791 - val_loss: 0.3716 - val_acc: 0.8600 - val_f1: 0.4898\n",
      "Epoch 3/5\n",
      "8000/8000 [==============================] - 3s 316us/step - loss: 0.3882 - acc: 0.8413 - f1: 0.3969 - val_loss: 0.3648 - val_acc: 0.8610 - val_f1: 0.4976\n",
      "Epoch 4/5\n",
      "8000/8000 [==============================] - 3s 378us/step - loss: 0.3831 - acc: 0.8439 - f1: 0.4171 - val_loss: 0.3603 - val_acc: 0.8645 - val_f1: 0.5190\n",
      "Epoch 5/5\n",
      "8000/8000 [==============================] - 3s 314us/step - loss: 0.3780 - acc: 0.8436 - f1: 0.4403 - val_loss: 0.3572 - val_acc: 0.8665 - val_f1: 0.5274\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f487588cf60>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "classifier.fit(X_train,\n",
    "               y_train,\n",
    "               batch_size = 32,\n",
    "               epochs = 5,\n",
    "               validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 2s 277us/step - loss: 0.3757 - acc: 0.8460 - f1: 0.4486 - val_loss: 0.3539 - val_acc: 0.8680 - val_f1: 0.5366\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 2s 269us/step - loss: 0.3747 - acc: 0.8486 - f1: 0.4569 - val_loss: 0.3516 - val_acc: 0.8640 - val_f1: 0.5300\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 299us/step - loss: 0.3701 - acc: 0.8476 - f1: 0.4705 - val_loss: 0.3487 - val_acc: 0.8645 - val_f1: 0.5320\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 3s 317us/step - loss: 0.3742 - acc: 0.8466 - f1: 0.4661 - val_loss: 0.3492 - val_acc: 0.8640 - val_f1: 0.5472\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 3s 323us/step - loss: 0.3701 - acc: 0.8470 - f1: 0.4620 - val_loss: 0.3480 - val_acc: 0.8650 - val_f1: 0.5438\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 295us/step - loss: 0.3667 - acc: 0.8452 - f1: 0.4489 - val_loss: 0.3466 - val_acc: 0.8640 - val_f1: 0.5488\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 3s 314us/step - loss: 0.3697 - acc: 0.8473 - f1: 0.4753 - val_loss: 0.3458 - val_acc: 0.8650 - val_f1: 0.5515\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 3s 385us/step - loss: 0.3650 - acc: 0.8489 - f1: 0.4661 - val_loss: 0.3461 - val_acc: 0.8650 - val_f1: 0.5564\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 3s 417us/step - loss: 0.3662 - acc: 0.8490 - f1: 0.4802 - val_loss: 0.3437 - val_acc: 0.8635 - val_f1: 0.5381\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 3s 409us/step - loss: 0.3647 - acc: 0.8479 - f1: 0.4857 - val_loss: 0.3439 - val_acc: 0.8650 - val_f1: 0.5545\n"
     ]
    }
   ],
   "source": [
    "# Fitting the ANN to the Training set\n",
    "history = classifier.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size = 32, \n",
    "                         epochs = 10,\n",
    "                         validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "his_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_acc</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>loss</th>\n",
       "      <th>acc</th>\n",
       "      <th>f1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.353921</td>\n",
       "      <td>0.8680</td>\n",
       "      <td>0.536606</td>\n",
       "      <td>0.375675</td>\n",
       "      <td>0.846000</td>\n",
       "      <td>0.448650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.351593</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.529951</td>\n",
       "      <td>0.374749</td>\n",
       "      <td>0.848625</td>\n",
       "      <td>0.456906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.348680</td>\n",
       "      <td>0.8645</td>\n",
       "      <td>0.532045</td>\n",
       "      <td>0.370067</td>\n",
       "      <td>0.847625</td>\n",
       "      <td>0.470491</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.349196</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.547192</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.846625</td>\n",
       "      <td>0.466117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.348015</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.543843</td>\n",
       "      <td>0.370053</td>\n",
       "      <td>0.847000</td>\n",
       "      <td>0.462003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.346577</td>\n",
       "      <td>0.8640</td>\n",
       "      <td>0.548771</td>\n",
       "      <td>0.366701</td>\n",
       "      <td>0.845250</td>\n",
       "      <td>0.448937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.345810</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.551507</td>\n",
       "      <td>0.369694</td>\n",
       "      <td>0.847250</td>\n",
       "      <td>0.475291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.346061</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.556417</td>\n",
       "      <td>0.365025</td>\n",
       "      <td>0.848875</td>\n",
       "      <td>0.466140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.343662</td>\n",
       "      <td>0.8635</td>\n",
       "      <td>0.538120</td>\n",
       "      <td>0.366169</td>\n",
       "      <td>0.849000</td>\n",
       "      <td>0.480222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.343930</td>\n",
       "      <td>0.8650</td>\n",
       "      <td>0.554526</td>\n",
       "      <td>0.364747</td>\n",
       "      <td>0.847875</td>\n",
       "      <td>0.485747</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   val_loss  val_acc    val_f1      loss       acc        f1\n",
       "0  0.353921   0.8680  0.536606  0.375675  0.846000  0.448650\n",
       "1  0.351593   0.8640  0.529951  0.374749  0.848625  0.456906\n",
       "2  0.348680   0.8645  0.532045  0.370067  0.847625  0.470491\n",
       "3  0.349196   0.8640  0.547192  0.374166  0.846625  0.466117\n",
       "4  0.348015   0.8650  0.543843  0.370053  0.847000  0.462003\n",
       "5  0.346577   0.8640  0.548771  0.366701  0.845250  0.448937\n",
       "6  0.345810   0.8650  0.551507  0.369694  0.847250  0.475291\n",
       "7  0.346061   0.8650  0.556417  0.365025  0.848875  0.466140\n",
       "8  0.343662   0.8635  0.538120  0.366169  0.849000  0.480222\n",
       "9  0.343930   0.8650  0.554526  0.364747  0.847875  0.485747"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "his_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 11)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 11)                132       \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 6)                 72        \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 6)                 0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 7         \n",
      "=================================================================\n",
      "Total params: 211\n",
      "Trainable params: 211\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "input_layer = Input(shape=(input_shape,))\n",
    "\n",
    "hidden1 = Dense(units = X_train.shape[1],kernel_initializer = 'uniform',\n",
    "                activation = 'relu')(input_layer)\n",
    "hidden2 = Dense(units = 6,kernel_initializer = 'uniform',\n",
    "                activation = 'relu')(hidden1)\n",
    "dropout = Dropout(rate=0.2)(hidden2)\n",
    "output_layer = Dense(units = 1,kernel_initializer = 'uniform',\n",
    "                activation = 'sigmoid')(dropout)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Compiling the ANN\n",
    "model.compile(optimizer = 'adamax', loss = 'binary_crossentropy', metrics = ['accuracy',f1])\n",
    "\n",
    "# summarize layers\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model, to_file='model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(classifier, to_file='classifier.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000 samples, validate on 2000 samples\n",
      "Epoch 1/10\n",
      "8000/8000 [==============================] - 3s 405us/step - loss: 0.5863 - acc: 0.7940 - f1: 6.4000e-04 - val_loss: 0.4553 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 2/10\n",
      "8000/8000 [==============================] - 3s 360us/step - loss: 0.4504 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4321 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 3/10\n",
      "8000/8000 [==============================] - 2s 302us/step - loss: 0.4395 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4267 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 4/10\n",
      "8000/8000 [==============================] - 2s 305us/step - loss: 0.4371 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4247 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 5/10\n",
      "8000/8000 [==============================] - 3s 329us/step - loss: 0.4345 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4219 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 6/10\n",
      "8000/8000 [==============================] - 2s 307us/step - loss: 0.4313 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4198 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 7/10\n",
      "8000/8000 [==============================] - 2s 286us/step - loss: 0.4292 - acc: 0.7960 - f1: 0.0000e+00 - val_loss: 0.4175 - val_acc: 0.7975 - val_f1: 0.0000e+00\n",
      "Epoch 8/10\n",
      "8000/8000 [==============================] - 3s 358us/step - loss: 0.4288 - acc: 0.8105 - f1: 0.1297 - val_loss: 0.4156 - val_acc: 0.8235 - val_f1: 0.2328\n",
      "Epoch 9/10\n",
      "8000/8000 [==============================] - 3s 352us/step - loss: 0.4277 - acc: 0.8230 - f1: 0.2709 - val_loss: 0.4127 - val_acc: 0.8315 - val_f1: 0.3064\n",
      "Epoch 10/10\n",
      "8000/8000 [==============================] - 3s 314us/step - loss: 0.4247 - acc: 0.8234 - f1: 0.2793 - val_loss: 0.4132 - val_acc: 0.8375 - val_f1: 0.3655\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4874c48a90>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, \n",
    "          y_train,\n",
    "          batch_size = 32,\n",
    "          epochs = 10,\n",
    "          validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function:f1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-72bd6bfdc08d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloaded_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Model.h5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/saving.py\u001b[0m in \u001b[0;36mload_model\u001b[0;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[1;32m    288\u001b[0m                           \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m                           \u001b[0mloss_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mloss_weights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                           sample_weight_mode=sample_weight_mode)\n\u001b[0m\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             \u001b[0;31m# Set optimizer weights.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    437\u001b[0m                 \u001b[0moutput_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    438\u001b[0m                 \u001b[0moutput_weighted_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 439\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    440\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    394\u001b[0m                     \u001b[0mmetric_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetric_name_prefix\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msuffix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 396\u001b[0;31m                     \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m                     \u001b[0mweighted_metric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweighted_masked_objective\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m                     \u001b[0;31m# Get metric name as string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 75\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     76\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     65\u001b[0m                                     \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                                     \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                                     printable_module_name='metric function')\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    163\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m                 raise ValueError('Unknown ' + printable_module_name +\n\u001b[0;32m--> 165\u001b[0;31m                                  ':' + function_name)\n\u001b[0m\u001b[1;32m    166\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown metric function:f1"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model(\"Model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 - Making predictions and evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.22698179],\n",
       "       [0.31629607],\n",
       "       [0.1657943 ],\n",
       "       ...,\n",
       "       [0.1703078 ],\n",
       "       [0.15399894],\n",
       "       [0.15634158]], dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict_classes(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting a single new observation\n",
    "\"\"\"Predict if the customer with the following informations will leave the bank:\n",
    "Geography: France\n",
    "Credit Score: 600\n",
    "Gender: Male\n",
    "Age: 40\n",
    "Tenure: 3\n",
    "Balance: 60000\n",
    "Number of Products: 2\n",
    "Has Credit Card: Yes\n",
    "Is Active Member: Yes\n",
    "Estimated Salary: 50000\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0]], dtype=int32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_prediction = classifier.predict_classes(sc.transform(np.array([[0.0, 0, 600, 1, 40, 3, 60000, 2, 1, 1, 50000]])))\n",
    "new_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating the Keras Model\n",
    "from sklearn.metrics import (confusion_matrix, accuracy_score, precision_score, \n",
    "                             recall_score, f1_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix for ANN: \n",
      " [[1546   49]\n",
      " [ 265  140]]\n",
      "Accuracy for ANN: \n",
      " 0.843\n",
      "Precision for ANN: \n",
      " 0.7407407407407407\n",
      "Recall for ANN: \n",
      " 0.345679012345679\n",
      "f1_score for ANN: \n",
      " 0.4713804713804714\n"
     ]
    }
   ],
   "source": [
    "print('Confusion Matrix for ANN: \\n',confusion_matrix(y_test, classifier.predict_classes(X_test)))\n",
    "print('Accuracy for ANN: \\n',accuracy_score(y_test, classifier.predict_classes(X_test)))\n",
    "print('Precision for ANN: \\n',precision_score(y_test, classifier.predict_classes(X_test)))\n",
    "print('Recall for ANN: \\n',recall_score(y_test, classifier.predict_classes(X_test)))\n",
    "print('f1_score for ANN: \\n',f1_score(y_test, classifier.predict_classes(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 - Hyperparameter tuning for the Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier():\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, input_dim=11, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = 'adam', \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=build_classifier, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tune for batch_size and number of epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters for batch_size and epochs\n",
    "batch_size = [100,200,500]\n",
    "epochs = [1,2,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': [100, 200, 500], 'epochs': [1, 2, 3]}"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_1 = dict(batch_size=batch_size, epochs=epochs)\n",
    "param_grid_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid = GridSearchCV(estimator=model, \n",
    "                    param_grid=param_grid_1, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result = grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier2(optimizer = 'adam'):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, activation = 'relu', input_dim=11))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    classifier.compile(optimizer = optimizer, \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = KerasClassifier(build_fn=build_classifier2, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = ['SGD', 'RMSprop', 'Adagrad', 'Adadelta', 'Adam', 'Adamax', 'Nadam']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'optimizer': ['SGD',\n",
       "  'RMSprop',\n",
       "  'Adagrad',\n",
       "  'Adadelta',\n",
       "  'Adam',\n",
       "  'Adamax',\n",
       "  'Nadam']}"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid_2 = dict(optimizer=optimizer)\n",
    "param_grid_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid2 = GridSearchCV(estimator=model2, \n",
    "                    param_grid=param_grid_2, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result2 = grid2.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=grid_result.best_params_['batch_size'],\n",
    "                         epochs=grid_result.best_params_['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best optimizer is: \",grid_result2.best_params_['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier3(learning_rate=0.01):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, activation = 'relu', input_dim=11))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    classifier.compile(optimizer = optimizer, \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model3 = KerasClassifier(build_fn=build_classifier3, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_3 = dict(learning_rate=learning_rate)\n",
    "param_grid_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid3 = GridSearchCV(estimator=model3, \n",
    "                    param_grid=param_grid_3, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result3 = grid3.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=grid_result.best_params_['batch_size'],\n",
    "                         epochs=grid_result.best_params_['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The optimum learning rate for the best optimizer is: \",grid_result3.best_params_['learning_rate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier4(init_mode='uniform'):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, , input_dim=11, kernel_initializer=init_mode, activation = 'relu'))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    classifier.compile(optimizer = optimizer, \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model4 = KerasClassifier(build_fn=build_classifier4, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "init_mode = ['uniform', 'lecun_uniform', 'normal', 'zero', 'glorot_normal', 'glorot_uniform', 'he_normal', 'he_uniform']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_4 = dict(init_mode=init_mode)\n",
    "param_grid_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid4 = GridSearchCV(estimator=model4, \n",
    "                    param_grid=param_grid_4, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result4 = grid4.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=grid_result.best_params_['batch_size'],\n",
    "                         epochs=grid_result.best_params_['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best weight initialization method is: \",grid_result4.best_params_['init_mode'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier5(activation1='relu', activation2='relu'):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(units = 6, input_dim=11, \n",
    "                         kernel_initializer=init_mode, \n",
    "                         activation = activation1))\n",
    "    classifier.add(Dense(units = 6, kernel_initializer=init_mode, \n",
    "                         activation = activation2))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    classifier.compile(optimizer = optimizer, \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model5 = KerasClassifier(build_fn=build_classifier5, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activation1 = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']\n",
    "activation2 = ['softmax', 'softplus', 'softsign', 'relu', 'tanh', 'sigmoid', 'hard_sigmoid', 'linear']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_5 = dict(activation=activation)\n",
    "param_grid_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid5 = GridSearchCV(estimator=model5, \n",
    "                    param_grid=param_grid_5, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result5 = grid5.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=grid_result.best_params_['batch_size'],\n",
    "                         epochs=grid_result.best_params_['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The best layer activation is: \",grid_result5.best_params_['activation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get the Keras Model\n",
    "def build_classifier6(neurons=1):\n",
    "    classifier = Sequential()\n",
    "    classifier.add(Dense(neurons, \n",
    "                         input_dim=11, \n",
    "                         kernel_initializer=init_mode, \n",
    "                         activation = activation))\n",
    "    classifier.add(Dense(units = 1, activation = 'sigmoid'))\n",
    "    optimizer = Adam(lr=learning_rate)\n",
    "    classifier.compile(optimizer = optimizer, \n",
    "                       loss = 'binary_crossentropy', \n",
    "                       metrics = ['accuracy'])\n",
    "    return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model6 = KerasClassifier(build_fn=build_classifier6, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [1, 5, 10, 15, 20, 25, 30]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid_6= dict(neurons=neurons)\n",
    "param_grid_6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid6 = GridSearchCV(estimator=model6, \n",
    "                    param_grid=param_grid_6, \n",
    "                    #cv=5,\n",
    "                    n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_result6 = grid6.fit(X_train, \n",
    "                         y_train, \n",
    "                         batch_size=grid_result.best_params_['batch_size'],\n",
    "                         epochs=grid_result.best_params_['epochs'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"The optimum number of neurons in hidden layer is: \",grid_result6.best_params_['neurons'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 5 - Create the Tuned Keras Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 6 - Make Predictions and Evaluate Tuned Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
